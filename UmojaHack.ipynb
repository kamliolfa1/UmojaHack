{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "UmojaHack.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9V5PH4bRQTC"
      },
      "source": [
        "import pandas as  pd \n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os \n",
        "from sklearn.model_selection import train_test_split\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hsKhYt6RQTM"
      },
      "source": [
        "### Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em7ePoomRQTO"
      },
      "source": [
        "def write_to_txt(file_name,column):\n",
        "    with open(file_name, 'w') as f:\n",
        "        for item in column:\n",
        "            f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca7NiX2MR1KQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "a15223d0-1ab1-4d94-f561-82fa9c6cf770"
      },
      "source": [
        "pip install PyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIuuqlh6R1Sl"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJaZWEkSR1YX"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnV0x4RKR1dj"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"17Noh_WLmNY7XRGwVong641aj2mZxbmWl\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('train.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_31cdl0_R1WS"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"17S3ghO_EuSn2xSPZw3zy6Nw5t0FwKoyr\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('test.csv')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG7ZC8Y4RQTa"
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIfIJeJ-SQEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "618d456a-8a76-40b4-ed6b-257e05a34f00"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_test_0</td>\n",
              "      <td>MSIRKRLTWQFTLIVTSILVLFFVFIYIFYADFRREEYYSRLYNKA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_test_1</td>\n",
              "      <td>MRWGILVNLAIILFVSGVLLFIAFCASLERAAVDSRVYQAAVLFEA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_test_2</td>\n",
              "      <td>MNLQNYYETVMELSHGIVVALDLNGGIIHGNSELVAMSGYTIEELA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_test_3</td>\n",
              "      <td>MRMLMSSLVLVVLATIAGLGWSISEFAALQNQDTATANVNSRIAAL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_test_4</td>\n",
              "      <td>MIKEYAKQMVSLLFLLSGIALSSSAQKQQVWKPFYDKCRREKSIID...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID                                           Sequence\n",
              "0  ID_test_0  MSIRKRLTWQFTLIVTSILVLFFVFIYIFYADFRREEYYSRLYNKA...\n",
              "1  ID_test_1  MRWGILVNLAIILFVSGVLLFIAFCASLERAAVDSRVYQAAVLFEA...\n",
              "2  ID_test_2  MNLQNYYETVMELSHGIVVALDLNGGIIHGNSELVAMSGYTIEELA...\n",
              "3  ID_test_3  MRMLMSSLVLVVLATIAGLGWSISEFAALQNQDTATANVNSRIAAL...\n",
              "4  ID_test_4  MIKEYAKQMVSLLFLLSGIALSSSAQKQQVWKPFYDKCRREKSIID..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSmF2seZRQTi"
      },
      "source": [
        "max_seq_length = 550 # max seq length in this data set is 550 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOAdNkCkRQTv"
      },
      "source": [
        "# split data to train and validation \n",
        "train, val = train_test_split(train,test_size=0.1,random_state=1994)\n",
        "\n",
        "# reduce seq length\n",
        "if max_seq_length>550 : \n",
        "    train[\"Sequence\"] = train[\"Sequence\"].apply(lambda x: \"\".join(list(x)[0:max_seq_length]))\n",
        "    val[\"Sequence\"] = val[\"Sequence\"].apply(lambda x: \"\".join(list(x)[0:max_seq_length]))\n",
        "    test[\"Sequence\"] = test[\"Sequence\"].apply(lambda x: \"\".join(list(x)[0:max_seq_length]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxTAdMU_SYuk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9cf7134b-2895-4133-e5c6-9c462f76d747"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>189739</th>\n",
              "      <td>ID_train_189739</td>\n",
              "      <td>MEKEPEPERMVKVVRSHDDSIKLLSCRYRSSGYLTALMAALQDTND...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427390</th>\n",
              "      <td>ID_train_427390</td>\n",
              "      <td>MVSILAMVIIILPVIAVIIMNSFEKHMVRSIENELSAYSYSILAVA...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133827</th>\n",
              "      <td>ID_train_133827</td>\n",
              "      <td>MDFENGAHVRRAQARVGTVLSGVWRLDALVGLGGMAAVYAATHRSG...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21175</th>\n",
              "      <td>ID_train_21175</td>\n",
              "      <td>MTTQTSVIYVISDALGETAEFVSRAAAAQFIGVKTRIRRVPYVRDQ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204839</th>\n",
              "      <td>ID_train_204839</td>\n",
              "      <td>MLWANRRRLRDYAKVGRQLLFQRIAIYSAAIFLAGAYYNWKIALIF...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     ID  ... target\n",
              "189739  ID_train_189739  ...      1\n",
              "427390  ID_train_427390  ...      2\n",
              "133827  ID_train_133827  ...      1\n",
              "21175    ID_train_21175  ...      5\n",
              "204839  ID_train_204839  ...      2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNncgnYcRQT3"
      },
      "source": [
        "# write Sequence column to txt file \n",
        "write_to_txt(\"train.txt\",train.Sequence)\n",
        "write_to_txt(\"test.txt\",test.Sequence)\n",
        "write_to_txt(\"val.txt\",val.Sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vndl05URQT-"
      },
      "source": [
        "train_label = train[[\"target\"]].copy()\n",
        "val_label = val[[\"target\"]].copy()\n",
        "train_label.to_csv(\"train_label.csv\",index=False)\n",
        "val_label.to_csv(\"val_label.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfa_UMA-RQUF"
      },
      "source": [
        "### Data loaders "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PyfHPG_RQUH"
      },
      "source": [
        "train_label = pd.read_csv(\"train_label.csv\")\n",
        "val_label = pd.read_csv(\"val_label.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s96vifWkRQUP"
      },
      "source": [
        "train_batch_size = 1024\n",
        "val_batch_size = 1024\n",
        "number_of_class = train_label.target.nunique()\n",
        "train_steps = len(train_label) // train_batch_size + int(len(train_label) % train_batch_size > 0)\n",
        "val_steps = len(val_label) // val_batch_size + int(len(val_label) % val_batch_size > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO8wFudCRQUW"
      },
      "source": [
        "voc_set = set(['P', 'V', 'I', 'K', 'N', 'B', 'F', 'Y', 'E', 'W', 'R', 'D', 'X', 'S', 'C', 'U', 'Q', 'A', 'M', 'H', 'L', 'G', 'T'])\n",
        "voc_set_map = { k:v for k , v in zip(voc_set,range(1,len(voc_set)+1))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt08a-iLRQUc"
      },
      "source": [
        "def encode(text_tensor, label):\n",
        "    encoded_text = [ voc_set_map[e] for e in list(text_tensor.numpy().decode())]\n",
        "    return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "    # py_func doesn't set the shape of the returned tensors.\n",
        "    encoded_text, label = tf.py_function(encode, \n",
        "                                       inp=[text, label], \n",
        "                                       Tout=(tf.int64, tf.int64))\n",
        "    encoded_text.set_shape([None])\n",
        "    label = tf.one_hot(label,number_of_class)\n",
        "    label.set_shape([number_of_class])\n",
        "    \n",
        "    return encoded_text, label\n",
        "\n",
        "def get_data_loader(file,batch_size,labels):\n",
        "    # data_set=tf.data.Dataset.from_tensor_slices((df.Sequence,df.target))\n",
        "    \n",
        "    label_data = tf.data.Dataset.from_tensor_slices(labels.target)\n",
        "    data_set = tf.data.TextLineDataset(file)\n",
        "    data_set = tf.data.Dataset.zip((data_set,label_data))\n",
        "\n",
        "    data_set = data_set.repeat()\n",
        "    data_set = data_set.shuffle(len(labels))\n",
        "    data_set = data_set.map(encode_map_fn,tf.data.experimental.AUTOTUNE)\n",
        "    data_set = data_set.padded_batch(batch_size)\n",
        "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return data_set\n",
        "\n",
        "def get_test_data_loader(file,batch_size):\n",
        "    data_set=tf.data.TextLineDataset(file)\n",
        "    data_set=train_data_loader.map(encode_map_fn,tf.data.experimental.AUTOTUNE)\n",
        "    data_set=data_set.padded_batch(batch_size)\n",
        "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return data_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTbg5bTjRQUi"
      },
      "source": [
        "train_dl = get_data_loader(\"train.txt\",train_batch_size,train_label)\n",
        "val_dl = get_data_loader(\"val.txt\",train_batch_size,val_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJn3qvTwRQUp"
      },
      "source": [
        "### Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ehaLrHRQUq"
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Dropout,Embedding,Concatenate,Flatten,LSTM ,Bidirectional\n",
        "from tensorflow.keras.activations import relu ,sigmoid,softmax\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "def model():\n",
        "    name = \"seq\"\n",
        "    dropout_rate = 0.1\n",
        "    learning_rate = 0.001\n",
        "    sequnce = Input([None],name=\"sequnce\")\n",
        "    \n",
        "    EMB_layer = Embedding(input_dim = len(voc_set)+1, output_dim = 64, name = \"emb_layer\")\n",
        "\n",
        "    LSTM_layer_2 = LSTM(units=256, name = \"lstm_2\", return_sequences = False)\n",
        "    BIDIR_layer_2 = Bidirectional(LSTM_layer_2, name=\"bidirectional_2\")\n",
        "    \n",
        "    Dens_layer_1 = Dense(units=512, activation=relu, kernel_regularizer=None, bias_regularizer=None, name=name+\"_dense_layer_1\")\n",
        "    Dens_layer_2 = Dense(units=256, activation=relu, kernel_regularizer=None, bias_regularizer=None, name=name+\"_dense_layer_2\")\n",
        "    \n",
        "    output = Dense(units=number_of_class, activation=softmax, kernel_regularizer=None, bias_regularizer=None, name=name+\"_dense_layer_output\")\n",
        "    \n",
        "    dropout_1 = Dropout(dropout_rate)\n",
        "    \n",
        "    \n",
        "    emb_layer = EMB_layer(sequnce)\n",
        "    logits = output(Dens_layer_2(dropout_1(Dens_layer_1(BIDIR_layer_2(emb_layer)))))\n",
        "\n",
        "    \n",
        "    model = tf.keras.Model(inputs={\"sequnce\":sequnce, },outputs=logits) \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"Acc\")]) \n",
        "    model.summary()\n",
        "    return model \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rJabkNoRQUy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "80c48a9a-4b42-4b18-b927-64b37898f1a1"
      },
      "source": [
        "model=model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequnce (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "emb_layer (Embedding)        (None, None, 64)          1536      \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 512)               657408    \n",
            "_________________________________________________________________\n",
            "seq_dense_layer_1 (Dense)    (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "seq_dense_layer_2 (Dense)    (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "seq_dense_layer_output (Dens (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 1,054,984\n",
            "Trainable params: 1,054,984\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKX_2edURQU7"
      },
      "source": [
        "# you can add early stoping method as callback and save best model to improve your score "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbCaARnWciiJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8a3dc121-6451-4855-ea98-6abb3ca70222"
      },
      "source": [
        "history = model.fit(train_dl,\n",
        "                    validation_data=val_dl,\n",
        "                    epochs=4,\n",
        "                    verbose=1,\n",
        "                    validation_steps=val_steps,\n",
        "                    steps_per_epoch=train_steps\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "360/360 [==============================] - 382s 1s/step - loss: 0.7660 - Acc: 0.7424 - val_loss: 0.5142 - val_Acc: 0.8185\n",
            "Epoch 2/4\n",
            "360/360 [==============================] - 388s 1s/step - loss: 0.5092 - Acc: 0.8221 - val_loss: 0.3789 - val_Acc: 0.8612\n",
            "Epoch 3/4\n",
            "360/360 [==============================] - 388s 1s/step - loss: 0.4368 - Acc: 0.8475 - val_loss: 0.3302 - val_Acc: 0.8842\n",
            "Epoch 4/4\n",
            "360/360 [==============================] - 389s 1s/step - loss: 0.3934 - Acc: 0.8604 - val_loss: 0.3794 - val_Acc: 0.8684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49EDVbHlrEgW"
      },
      "source": [
        "def encode(text_tensor, label):\n",
        "    encoded_text = [ voc_set_map[e] for e in list(text_tensor.numpy().decode())]\n",
        "    return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "    # py_func doesn't set the shape of the returned tensors.\n",
        "    encoded_text, label = tf.py_function(encode, \n",
        "                                       inp=[text, label], \n",
        "                                       Tout=(tf.int64, tf.int64))\n",
        "    encoded_text.set_shape([None])\n",
        "    label = tf.one_hot(label,number_of_class)\n",
        "    label.set_shape([number_of_class])\n",
        "    \n",
        "    return encoded_text, label\n",
        "\n",
        "def get_data_loader(file,batch_size,labels):\n",
        "    # data_set=tf.data.Dataset.from_tensor_slices((df.Sequence,df.target))\n",
        "    \n",
        "    label_data = tf.data.Dataset.from_tensor_slices(labels.target)\n",
        "    data_set = tf.data.TextLineDataset(file)\n",
        "    data_set = tf.data.Dataset.zip((data_set,label_data))\n",
        "\n",
        "    data_set = data_set.repeat()\n",
        "    data_set = data_set.shuffle(len(labels))\n",
        "    data_set = data_set.map(encode_map_fn,tf.data.experimental.AUTOTUNE)\n",
        "    data_set = data_set.padded_batch(batch_size)\n",
        "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return data_set\n",
        "\n",
        "def get_test_data_loader(file,batch_size):\n",
        "    data_set=tf.data.TextLineDataset(file)\n",
        "    data_set=train_data_loader.map(encode_map_fn,tf.data.experimental.AUTOTUNE)\n",
        "    data_set=data_set.padded_batch(batch_size)\n",
        "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return data_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7aDvCBtWphn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "2ed57430-46b5-4d36-9e40-58917047129c"
      },
      "source": [
        "test_dl = get_test_data_loader(\"test.txt\",512)\n",
        "test_pred = model.predict(test_dl,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-2f2a0dc57917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-4498ade62394>\u001b[0m in \u001b[0;36mget_test_data_loader\u001b[0;34m(file, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_test_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextLineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_map_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeaPKtDHRQVO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "2efc5e1a-6609-48d9-de8c-7a2394252215"
      },
      "source": [
        "sub = test[[\"ID\"]].copy()\n",
        "for i in range(number_of_class):\n",
        "    sub[\"target_{}\".format(i)]=test_pred[:,i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-bd8839420f70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC5BHz2zRQVV"
      },
      "source": [
        "sub.to_csv(\"StarterNotebookDL_sub.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}